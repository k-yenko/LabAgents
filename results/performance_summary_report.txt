Agentic AI Model Performance on Computational Chemistry Benchmarks
===========================================================================

1. Overall Performance on Multi-Step Computational Chemistry Tasks:
   (N=10 questions spanning molecular property prediction, conformational analysis,
    and protein-ligand interaction studies)

   Claude 4.1 Opus     3/10 ( 30%)
   Claude 4 Sonnet     4/10 ( 40%)
   GPT-5               6/10 ( 60%)
   o3                  5/10 ( 50%)
   Grok-4              5/10 ( 50%)
   Gemini 2.5 Pro      4/10 ( 40%)
   DeepSeek v3.1       0/10 (  0%)
   Grok Code Fast-1    3/10 ( 30%)

2. Tier 2 Performance - Intermediate Complexity Tasks:
   (N=5 questions: molecular descriptors, conformer analysis, pKa prediction)

   Claude 4.1 Opus     2/5 ( 40%)
   Claude 4 Sonnet     2/5 ( 40%)
   GPT-5               4/5 ( 80%)
   o3                  4/5 ( 80%)
   Grok-4              4/5 ( 80%)
   Gemini 2.5 Pro      3/5 ( 60%)
   DeepSeek v3.1       0/5 (  0%)
   Grok Code Fast-1    1/5 ( 20%)

3. Tier 3 Performance - Advanced Multi-Step Workflows:
   (N=5 questions: tautomer analysis, ADMET prediction, molecular docking)

   Claude 4.1 Opus     1/5 ( 20%)
   Claude 4 Sonnet     2/5 ( 40%)
   GPT-5               2/5 ( 40%)
   o3                  1/5 ( 20%)
   Grok-4              1/5 ( 20%)
   Gemini 2.5 Pro      1/5 ( 20%)
   DeepSeek v3.1       0/5 (  0%)
   Grok Code Fast-1    2/5 ( 40%)

4. Task Difficulty Analysis (Cross-Model Success Rates):
   Proportion of models successfully completing each task:

   Tier 2 Tasks:
   tier2_002     7/8 models ( 88%)
   tier2_003     4/8 models ( 50%)
   tier2_004     5/8 models ( 62%)
   tier2_005     2/8 models ( 25%)
   tier2_007     2/8 models ( 25%)

   Tier 3 Tasks:
   tier3_001     1/8 models ( 12%)
   tier3_002     6/8 models ( 75%)
   tier3_003     0/8 models (  0%)
   tier3_004     0/8 models (  0%)
   tier3_005     3/8 models ( 38%)

==========================================================================================
TABLE 1. Agentic AI Model Performance on Computational Chemistry Benchmarks
==========================================================================================

Performance evaluation of large language models with agentic capabilities
on multi-step computational chemistry tasks requiring tool use and domain expertise.

Model                Tier 2       Tier 3       Overall      Success Rate
                     (N=5)        (N=5)        (N=10)      
---------------------------------------------------------------------------
Claude 4.1 Opus      2/5        1/5        3/10         30%
Claude 4 Sonnet      2/5        2/5        4/10         40%
GPT-5                4/5        2/5        6/10         60%
o3                   4/5        1/5        5/10         50%
Grok-4               4/5        1/5        5/10         50%
Gemini 2.5 Pro       3/5        1/5        4/10         40%
DeepSeek v3.1        0/5        0/5        0/10          0%
Grok Code Fast-1     1/5        2/5        3/10         30%
---------------------------------------------------------------------------

Tier 2: Intermediate complexity tasks (conformer generation, molecular descriptors,
        pKa prediction, solubility calculations)
Tier 3: Advanced multi-step workflows (tautomer enumeration, ADMET prediction,
        protein-ligand docking, Fukui indices calculation)

Success rates represent the proportion of tasks completed correctly according to
domain expert evaluation against literature benchmarks and experimental data.
